{
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.12",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "none",
      "dataSources": [
        {
          "sourceId": 2952837,
          "sourceType": "datasetVersion",
          "datasetId": 1794621
        },
        {
          "sourceId": 6106,
          "sourceType": "modelInstanceVersion",
          "modelInstanceId": 4649,
          "modelId": 2804
        }
      ],
      "dockerImageVersionId": 30918,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": false
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "nbformat_minor": 5,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tcc3281/ATBMTT_code/blob/main/YOLOv8_Traffic_Sign_Detector.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "source": [
        "# IMPORTANT: RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES,\n",
        "# THEN FEEL FREE TO DELETE THIS CELL.\n",
        "# NOTE: THIS NOTEBOOK ENVIRONMENT DIFFERS FROM KAGGLE'S PYTHON\n",
        "# ENVIRONMENT SO THERE MAY BE MISSING LIBRARIES USED BY YOUR\n",
        "# NOTEBOOK.\n",
        "import kagglehub\n",
        "ahemateja19bec1025_trafficsignlocalizationdetectionyoloannotated_path = kagglehub.dataset_download('ahemateja19bec1025/trafficsignlocalizationdetectionyoloannotated')\n",
        "keras_yolov8_keras_yolo_v8_s_backbone_coco_2_path = kagglehub.model_download('keras/yolov8/Keras/yolo_v8_s_backbone_coco/2')\n",
        "\n",
        "print('Data source import complete.')\n"
      ],
      "metadata": {
        "id": "XGS8Zgo3Gg3z",
        "outputId": "ea79a20e-8b27-4b25-a596-ee716d378a86",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "cell_type": "code",
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data source import complete.\n"
          ]
        }
      ],
      "execution_count": 43,
      "id": "XGS8Zgo3Gg3z"
    },
    {
      "cell_type": "code",
      "source": [
        "ahemateja19bec1025_trafficsignlocalizationdetectionyoloannotated_path"
      ],
      "metadata": {
        "id": "L0HujzAKG8jS",
        "outputId": "9b2a8a19-3707-421c-9782-ad03a4d75275",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "id": "L0HujzAKG8jS",
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/root/.cache/kagglehub/datasets/ahemateja19bec1025/trafficsignlocalizationdetectionyoloannotated/versions/9'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!!pip install keras-cv"
      ],
      "metadata": {
        "id": "D2HY8aEaHat4",
        "outputId": "dc565ac0-2cd8-4dc9-fead-a7a2634c1fb5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "D2HY8aEaHat4",
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Requirement already satisfied: keras-cv in /usr/local/lib/python3.11/dist-packages (0.9.0)',\n",
              " 'Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from keras-cv) (24.2)',\n",
              " 'Requirement already satisfied: absl-py in /usr/local/lib/python3.11/dist-packages (from keras-cv) (1.4.0)',\n",
              " 'Requirement already satisfied: regex in /usr/local/lib/python3.11/dist-packages (from keras-cv) (2024.11.6)',\n",
              " 'Requirement already satisfied: tensorflow-datasets in /usr/local/lib/python3.11/dist-packages (from keras-cv) (4.9.7)',\n",
              " 'Requirement already satisfied: keras-core in /usr/local/lib/python3.11/dist-packages (from keras-cv) (0.1.7)',\n",
              " 'Requirement already satisfied: kagglehub in /usr/local/lib/python3.11/dist-packages (from keras-cv) (0.3.10)',\n",
              " 'Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from kagglehub->keras-cv) (6.0.2)',\n",
              " 'Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from kagglehub->keras-cv) (2.32.3)',\n",
              " 'Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from kagglehub->keras-cv) (4.67.1)',\n",
              " 'Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from keras-core->keras-cv) (1.26.4)',\n",
              " 'Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from keras-core->keras-cv) (13.9.4)',\n",
              " 'Requirement already satisfied: namex in /usr/local/lib/python3.11/dist-packages (from keras-core->keras-cv) (0.0.8)',\n",
              " 'Requirement already satisfied: h5py in /usr/local/lib/python3.11/dist-packages (from keras-core->keras-cv) (3.12.1)',\n",
              " 'Requirement already satisfied: dm-tree in /usr/local/lib/python3.11/dist-packages (from keras-core->keras-cv) (0.1.9)',\n",
              " 'Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from tensorflow-datasets->keras-cv) (8.1.8)',\n",
              " 'Requirement already satisfied: immutabledict in /usr/local/lib/python3.11/dist-packages (from tensorflow-datasets->keras-cv) (4.2.1)',\n",
              " 'Requirement already satisfied: promise in /usr/local/lib/python3.11/dist-packages (from tensorflow-datasets->keras-cv) (2.3)',\n",
              " 'Requirement already satisfied: protobuf>=3.20 in /usr/local/lib/python3.11/dist-packages (from tensorflow-datasets->keras-cv) (4.25.6)',\n",
              " 'Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from tensorflow-datasets->keras-cv) (5.9.5)',\n",
              " 'Requirement already satisfied: pyarrow in /usr/local/lib/python3.11/dist-packages (from tensorflow-datasets->keras-cv) (18.1.0)',\n",
              " 'Requirement already satisfied: simple-parsing in /usr/local/lib/python3.11/dist-packages (from tensorflow-datasets->keras-cv) (0.1.7)',\n",
              " 'Requirement already satisfied: tensorflow-metadata in /usr/local/lib/python3.11/dist-packages (from tensorflow-datasets->keras-cv) (1.16.1)',\n",
              " 'Requirement already satisfied: termcolor in /usr/local/lib/python3.11/dist-packages (from tensorflow-datasets->keras-cv) (2.5.0)',\n",
              " 'Requirement already satisfied: toml in /usr/local/lib/python3.11/dist-packages (from tensorflow-datasets->keras-cv) (0.10.2)',\n",
              " 'Requirement already satisfied: wrapt in /usr/local/lib/python3.11/dist-packages (from tensorflow-datasets->keras-cv) (1.17.2)',\n",
              " 'Requirement already satisfied: array-record>=0.5.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow-datasets->keras-cv) (0.6.0)',\n",
              " 'Requirement already satisfied: etils>=1.9.1 in /usr/local/lib/python3.11/dist-packages (from etils[edc,enp,epath,epy,etree]>=1.9.1; python_version >= \"3.11\"->tensorflow-datasets->keras-cv) (1.12.1)',\n",
              " 'Requirement already satisfied: einops in /usr/local/lib/python3.11/dist-packages (from etils[edc,enp,epath,epy,etree]>=1.9.1; python_version >= \"3.11\"->tensorflow-datasets->keras-cv) (0.8.1)',\n",
              " 'Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from etils[edc,enp,epath,epy,etree]>=1.9.1; python_version >= \"3.11\"->tensorflow-datasets->keras-cv) (2024.10.0)',\n",
              " 'Requirement already satisfied: importlib_resources in /usr/local/lib/python3.11/dist-packages (from etils[edc,enp,epath,epy,etree]>=1.9.1; python_version >= \"3.11\"->tensorflow-datasets->keras-cv) (6.5.2)',\n",
              " 'Requirement already satisfied: typing_extensions in /usr/local/lib/python3.11/dist-packages (from etils[edc,enp,epath,epy,etree]>=1.9.1; python_version >= \"3.11\"->tensorflow-datasets->keras-cv) (4.12.2)',\n",
              " 'Requirement already satisfied: zipp in /usr/local/lib/python3.11/dist-packages (from etils[edc,enp,epath,epy,etree]>=1.9.1; python_version >= \"3.11\"->tensorflow-datasets->keras-cv) (3.21.0)',\n",
              " 'Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->kagglehub->keras-cv) (3.4.1)',\n",
              " 'Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->kagglehub->keras-cv) (3.10)',\n",
              " 'Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->kagglehub->keras-cv) (2.3.0)',\n",
              " 'Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->kagglehub->keras-cv) (2025.1.31)',\n",
              " 'Requirement already satisfied: attrs>=18.2.0 in /usr/local/lib/python3.11/dist-packages (from dm-tree->keras-core->keras-cv) (25.1.0)',\n",
              " 'Requirement already satisfied: six in /usr/local/lib/python3.11/dist-packages (from promise->tensorflow-datasets->keras-cv) (1.17.0)',\n",
              " 'Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras-core->keras-cv) (3.0.0)',\n",
              " 'Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras-core->keras-cv) (2.18.0)',\n",
              " 'Requirement already satisfied: docstring-parser<1.0,>=0.15 in /usr/local/lib/python3.11/dist-packages (from simple-parsing->tensorflow-datasets->keras-cv) (0.16)',\n",
              " 'Requirement already satisfied: googleapis-common-protos<2,>=1.56.4 in /usr/local/lib/python3.11/dist-packages (from tensorflow-metadata->tensorflow-datasets->keras-cv) (1.69.1)',\n",
              " 'Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->keras-core->keras-cv) (0.1.2)']"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "id": "initial_id",
      "cell_type": "code",
      "source": [
        "import keras_cv\n",
        "import keras_core as keras\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import *\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import *\n",
        "from keras_cv.models import YOLOV8Backbone, YOLOV8Detector\n",
        "import os\n",
        "from keras_cv.losses import YOLOV8Loss\n",
        "import numpy as np\n"
      ],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-03-12T06:28:06.103754Z",
          "start_time": "2025-03-12T06:27:47.846906Z"
        },
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-03-12T16:00:59.1048Z",
          "iopub.execute_input": "2025-03-12T16:00:59.105152Z",
          "iopub.status.idle": "2025-03-12T16:01:22.957945Z",
          "shell.execute_reply.started": "2025-03-12T16:00:59.105123Z",
          "shell.execute_reply": "2025-03-12T16:01:22.956945Z"
        },
        "id": "initial_id",
        "outputId": "32dcbac1-1c6e-4eef-df63-0e16d1c51b38",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 385
        }
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "ImportError",
          "evalue": "cannot import name 'YOLOV8Loss' from 'keras_cv.losses' (/usr/local/lib/python3.11/dist-packages/keras_cv/api/losses/__init__.py)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-48-82567f8ae169>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras_cv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mYOLOV8Backbone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mYOLOV8Detector\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras_cv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlosses\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mYOLOV8Loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mImportError\u001b[0m: cannot import name 'YOLOV8Loss' from 'keras_cv.losses' (/usr/local/lib/python3.11/dist-packages/keras_cv/api/losses/__init__.py)",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ],
      "execution_count": 48
    },
    {
      "cell_type": "code",
      "source": [
        "print(tf.__version__)  # Kiểm tra phiên bản TensorFlow"
      ],
      "metadata": {
        "id": "eTsp1Ddyb67K"
      },
      "id": "eTsp1Ddyb67K",
      "execution_count": null,
      "outputs": []
    },
    {
      "id": "7636b79f-bdf6-4ca4-9a4f-e21631e5a585",
      "cell_type": "markdown",
      "source": [
        "# 1. Preparing"
      ],
      "metadata": {
        "id": "7636b79f-bdf6-4ca4-9a4f-e21631e5a585"
      }
    },
    {
      "id": "0d69f466-ab92-4ee9-9c85-6a3f81688eb2",
      "cell_type": "code",
      "source": [
        "batch_size=8\n",
        "epochs=3"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-03-12T16:01:22.95907Z",
          "iopub.execute_input": "2025-03-12T16:01:22.959661Z",
          "iopub.status.idle": "2025-03-12T16:01:22.963754Z",
          "shell.execute_reply.started": "2025-03-12T16:01:22.959624Z",
          "shell.execute_reply": "2025-03-12T16:01:22.962507Z"
        },
        "id": "0d69f466-ab92-4ee9-9c85-6a3f81688eb2"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "dabf2f11-deee-42aa-899a-0b2bd900f98d",
      "cell_type": "code",
      "source": [
        "def parse_label_file(label_file_path, max_objects=10):\n",
        "    with open(label_file_path, 'r') as f:\n",
        "        lines = f.readlines()\n",
        "        classes = []\n",
        "        boxes = []\n",
        "        for line in lines[:max_objects]:  # Giới hạn số lượng objects\n",
        "            parts = line.strip().split()\n",
        "            if len(parts) != 5:\n",
        "                continue  # Bỏ qua dòng không hợp lệ\n",
        "\n",
        "            class_id = int(parts[0])\n",
        "            x_center = float(parts[1])\n",
        "            y_center = float(parts[2])\n",
        "            width = float(parts[3])\n",
        "            height = float(parts[4])\n",
        "\n",
        "            classes.append(class_id)\n",
        "            boxes.append([x_center, y_center, width, height])\n",
        "\n",
        "        # Padding\n",
        "        while len(classes) < max_objects:\n",
        "            classes.append(0)\n",
        "            boxes.append([0.0, 0.0, 0.0, 0.0])\n",
        "\n",
        "        return (\n",
        "            np.array(classes, dtype=np.int32),  # Shape (max_objects,)\n",
        "            np.array(boxes, dtype=np.float32)    # Shape (max_objects, 4)\n",
        "        )\n",
        "\n",
        "def load_image_and_labels(image_path, label_path, max_objects=10):\n",
        "    # Đọc ảnh\n",
        "    image = tf.io.read_file(image_path)\n",
        "    image = tf.image.decode_jpeg(image, channels=3)\n",
        "    image = tf.image.resize(image, [640, 640])\n",
        "    image = image / 255.0\n",
        "    image = tf.ensure_shape(image, [640, 640, 3])\n",
        "\n",
        "    # Đọc nhãn\n",
        "    def parse_label(path):\n",
        "        path_str = path.numpy().decode('utf-8')\n",
        "        classes, boxes = parse_label_file(path_str, max_objects)\n",
        "        return classes, boxes\n",
        "\n",
        "    classes, boxes = tf.py_function(\n",
        "        func=parse_label,\n",
        "        inp=[label_path],\n",
        "        Tout=[tf.int32, tf.float32]\n",
        "    )\n",
        "\n",
        "    # Cố định shape\n",
        "    classes = tf.ensure_shape(classes, [max_objects])  # Shape (max_objects,)\n",
        "    boxes = tf.ensure_shape(boxes, [max_objects, 4])   # Shape (max_objects, 4)\n",
        "\n",
        "    # Tạo dictionary labels\n",
        "    labels = {\n",
        "        \"classes\": classes,\n",
        "        \"boxes\": boxes\n",
        "    }\n",
        "\n",
        "    return image, labels  # CHỈ MỘT RETURN DUY NHẤT\n",
        "\n",
        "def create_dataset(image_dir, label_dir, batch_size=8, max_objects=10):\n",
        "    # Lấy danh sách file ảnh và nhãn\n",
        "    image_files = [os.path.join(image_dir, f) for f in os.listdir(image_dir) if f.endswith('.jpg')]\n",
        "    label_files = [os.path.join(label_dir, f.replace('.jpg', '.txt')) for f in image_files]\n",
        "\n",
        "    # Lọc file nhãn tồn tại\n",
        "    image_files = [img for img, lbl in zip(image_files, label_files) if os.path.exists(lbl)]\n",
        "    label_files = [lbl for lbl in label_files if os.path.exists(lbl)]\n",
        "\n",
        "    # Tạo dataset từ cặp (image_path, label_path) với kiểu dữ liệu string\n",
        "    dataset = tf.data.Dataset.from_tensor_slices(\n",
        "        (tf.constant(image_files, dtype=tf.string),  # Đảm bảo kiểu string\n",
        "         tf.constant(label_files, dtype=tf.string))  # Đảm bảo kiểu string\n",
        "    )\n",
        "\n",
        "    # Ánh xạ hàm load_image_and_labels\n",
        "    dataset = dataset.map(\n",
        "        lambda img_path, lbl_path: load_image_and_labels(img_path, lbl_path, max_objects),\n",
        "        num_parallel_calls=tf.data.AUTOTUNE\n",
        "    )\n",
        "\n",
        "    # Batch và prefetch\n",
        "    dataset = dataset.batch(batch_size,drop_remainder=True)\n",
        "    dataset = dataset.prefetch(1)\n",
        "\n",
        "    return dataset"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-03-12T16:01:22.965888Z",
          "iopub.execute_input": "2025-03-12T16:01:22.966216Z",
          "iopub.status.idle": "2025-03-12T16:01:22.993442Z",
          "shell.execute_reply.started": "2025-03-12T16:01:22.966189Z",
          "shell.execute_reply": "2025-03-12T16:01:22.992467Z"
        },
        "id": "dabf2f11-deee-42aa-899a-0b2bd900f98d"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "0a2e3916-fc74-4703-a4f4-3eb7dee47449",
      "cell_type": "code",
      "source": [
        "# train_image_dir = '/kaggle/input/trafficsignlocalizationdetectionyoloannotated/TrafficSignLocalizationandDetection/train/images'\n",
        "# train_label_dir = '/kaggle/input/trafficsignlocalizationdetectionyoloannotated/TrafficSignLocalizationandDetection/train/labels'\n",
        "# val_image_dir = '/kaggle/input/trafficsignlocalizationdetectionyoloannotated/TrafficSignLocalizationandDetection/valid/images'\n",
        "# val_label_dir = '/kaggle/input/trafficsignlocalizationdetectionyoloannotated/TrafficSignLocalizationandDetection/valid/labels'\n",
        "# test_image_dir = '/kaggle/input/trafficsignlocalizationdetectionyoloannotated/TrafficSignLocalizationandDetection/test/images'\n",
        "# test_label_dir = '/kaggle/input/trafficsignlocalizationdetectionyoloannotated/TrafficSignLocalizationandDetection/test/labels'\n",
        "\n",
        "train_image_dir = f'{ahemateja19bec1025_trafficsignlocalizationdetectionyoloannotated_path}/TrafficSignLocalizationandDetection/train/images'\n",
        "train_label_dir = f'{ahemateja19bec1025_trafficsignlocalizationdetectionyoloannotated_path}/TrafficSignLocalizationandDetection/train/labels'\n",
        "val_image_dir = f'{ahemateja19bec1025_trafficsignlocalizationdetectionyoloannotated_path}/TrafficSignLocalizationandDetection/valid/images'\n",
        "val_label_dir = f'{ahemateja19bec1025_trafficsignlocalizationdetectionyoloannotated_path}/TrafficSignLocalizationandDetection/valid/labels'\n",
        "test_image_dir = f'{ahemateja19bec1025_trafficsignlocalizationdetectionyoloannotated_path}/TrafficSignLocalizationandDetection/test/images'\n",
        "test_label_dir = f'{ahemateja19bec1025_trafficsignlocalizationdetectionyoloannotated_path}/TrafficSignLocalizationandDetection/test/labels'"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-03-12T16:01:22.99519Z",
          "iopub.execute_input": "2025-03-12T16:01:22.9956Z",
          "iopub.status.idle": "2025-03-12T16:01:23.019205Z",
          "shell.execute_reply.started": "2025-03-12T16:01:22.995541Z",
          "shell.execute_reply": "2025-03-12T16:01:23.018069Z"
        },
        "id": "0a2e3916-fc74-4703-a4f4-3eb7dee47449"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "5c0b4091-5bf6-4340-94a6-3b7aba86f3d1",
      "cell_type": "code",
      "source": [
        "num_classes=36"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-03-12T16:01:23.020279Z",
          "iopub.execute_input": "2025-03-12T16:01:23.020693Z",
          "iopub.status.idle": "2025-03-12T16:01:23.037359Z",
          "shell.execute_reply.started": "2025-03-12T16:01:23.020656Z",
          "shell.execute_reply": "2025-03-12T16:01:23.036299Z"
        },
        "id": "5c0b4091-5bf6-4340-94a6-3b7aba86f3d1"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "691d3aa6-4912-4f9e-a33f-c5c1fe4a05e5",
      "cell_type": "code",
      "source": [
        "train_dataset = create_dataset(train_image_dir, train_label_dir, batch_size=batch_size)\n",
        "val_dataset = create_dataset(val_image_dir, val_label_dir, batch_size=batch_size)\n",
        "test_dataset = create_dataset(test_image_dir, test_label_dir, batch_size=batch_size)\n",
        "\n",
        "# Kiểm tra shape\n",
        "for batch in train_dataset.take(1):\n",
        "    images = batch[0]\n",
        "    labels = batch[1]\n",
        "    print(\"Images shape:\", images.shape)  # (8, 640, 640, 3)\n",
        "    print(\"Classes shape:\", labels[\"classes\"].shape)  # (8, 10)\n",
        "    print(\"Boxes shape:\", labels[\"boxes\"].shape)  # (8, 10, 4)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-03-12T16:01:23.038462Z",
          "iopub.execute_input": "2025-03-12T16:01:23.038846Z",
          "iopub.status.idle": "2025-03-12T16:01:28.666087Z",
          "shell.execute_reply.started": "2025-03-12T16:01:23.038811Z",
          "shell.execute_reply": "2025-03-12T16:01:28.665051Z"
        },
        "id": "691d3aa6-4912-4f9e-a33f-c5c1fe4a05e5"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "for images, labels in train_dataset.take(1):\n",
        "    print(\"Dữ liệu từ train_dataset:\")\n",
        "    print(\"Shape ảnh:\", images.shape)  # (8, 640, 640, 3)\n",
        "    print(\"Shape classes:\", labels[\"classes\"].shape)  # (8, 10)\n",
        "    print(\"Shape boxes:\", labels[\"boxes\"].shape)      # (8, 10, 4)\n",
        "    break\n",
        "\n",
        "for images, labels in val_dataset.take(1):\n",
        "    print(\"\\nDữ liệu từ val_dataset:\")\n",
        "    print(\"Shape ảnh:\", images.shape)  # (8, 640, 640, 3)\n",
        "    print(\"Shape classes:\", labels[\"classes\"].shape)  # (8, 10)\n",
        "    print(\"Shape boxes:\", labels[\"boxes\"].shape)      # (8, 10, 4)\n",
        "    break"
      ],
      "metadata": {
        "id": "xqn2iBqbVCFc"
      },
      "id": "xqn2iBqbVCFc",
      "execution_count": null,
      "outputs": []
    },
    {
      "id": "16981c74-b80d-458a-abc5-f574be0ea10c",
      "cell_type": "markdown",
      "source": [
        "# 2. Model"
      ],
      "metadata": {
        "id": "16981c74-b80d-458a-abc5-f574be0ea10c"
      }
    },
    {
      "id": "7279c108-7c78-4365-8ee2-d987d25d8410",
      "cell_type": "code",
      "source": [
        "def create_model(pretrained=True, num_classes=80, input_shape=(batch_size, 224, 224, 3)):\n",
        "    # Tạo input\n",
        "    input_data = tf.ones(shape=input_shape)\n",
        "\n",
        "    if pretrained:\n",
        "        # Sử dụng backbone pretrained\n",
        "        backbone = YOLOV8Backbone.from_preset(\"yolo_v8_l_backbone_coco\")\n",
        "        fpn_depth = 2  # Độ sâu FPN phù hợp với preset 'l'\n",
        "    else:\n",
        "        # Backbone tự khởi tạo với cấu hình tuỳ chỉnh\n",
        "        backbone = YOLOV8Backbone(\n",
        "            stackwise_channels=[128, 256, 512, 1024],\n",
        "            stackwise_depth=[3, 9, 9, 3],\n",
        "            include_rescaling=False,\n",
        "        )\n",
        "        fpn_depth = 1  # Điều chỉnh theo kiến trúc\n",
        "\n",
        "    # Tạo detection model với backbone\n",
        "    detector = YOLOV8Detector(\n",
        "        num_classes=num_classes,\n",
        "        bounding_box_format=\"xywh\",\n",
        "        backbone=backbone,\n",
        "        fpn_depth=fpn_depth\n",
        "    )\n",
        "\n",
        "    # Forward pass\n",
        "    output = detector(input_data)\n",
        "\n",
        "    return detector"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-03-12T16:01:28.675661Z",
          "iopub.execute_input": "2025-03-12T16:01:28.67597Z",
          "iopub.status.idle": "2025-03-12T16:01:28.69474Z",
          "shell.execute_reply.started": "2025-03-12T16:01:28.675939Z",
          "shell.execute_reply": "2025-03-12T16:01:28.693567Z"
        },
        "id": "7279c108-7c78-4365-8ee2-d987d25d8410"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "a955e683-494f-4785-a3c4-a005b1e9485e",
      "cell_type": "code",
      "source": [
        "def create_light_model(\n",
        "    pretrained=True,\n",
        "    num_classes=36,\n",
        "    input_shape=(640, 640, 3)  # Sửa thành kích thước chuẩn (bội số của 32)\n",
        "):\n",
        "    # Khởi tạo backbone\n",
        "    if pretrained:\n",
        "        backbone = YOLOV8Backbone.from_preset(\"yolo_v8_s_backbone_coco\")\n",
        "        fpn_depth = 1\n",
        "    else:\n",
        "        backbone = YOLOV8Backbone(\n",
        "            stackwise_channels=[64, 128, 256, 512],\n",
        "            stackwise_depth=[2, 4, 4, 2],\n",
        "            include_rescaling=False,\n",
        "        )\n",
        "        fpn_depth = 1\n",
        "\n",
        "    # Tạo YOLOv8Detector với input_shape chính xác\n",
        "    detector = YOLOV8Detector(\n",
        "        num_classes=num_classes,\n",
        "        bounding_box_format=\"xywh\",\n",
        "        backbone=backbone,\n",
        "        fpn_depth=fpn_depth,\n",
        "        input_shape=input_shape  # Truyền input_shape trực tiếp vào detector\n",
        "    )\n",
        "\n",
        "    # Build model để khởi tạo trọng số\n",
        "    detector.build(input_shape=(None, *input_shape))  # Batch size là None\n",
        "\n",
        "    return detector"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-03-12T16:01:28.696096Z",
          "iopub.execute_input": "2025-03-12T16:01:28.696412Z",
          "iopub.status.idle": "2025-03-12T16:01:28.711185Z",
          "shell.execute_reply.started": "2025-03-12T16:01:28.696389Z",
          "shell.execute_reply": "2025-03-12T16:01:28.710249Z"
        },
        "id": "a955e683-494f-4785-a3c4-a005b1e9485e"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def create_ligh_model(num_classes=36):\n",
        "    inputs = Input(shape=(640, 640, 3), name=\"input_image\")\n",
        "    backbone = YOLOV8Backbone.from_preset(\"yolo_v8_s_backbone_coco\")\n",
        "    detector = YOLOV8Detector(\n",
        "        num_classes=num_classes,\n",
        "        bounding_box_format=\"xywh\",\n",
        "        backbone=backbone,\n",
        "        fpn_depth=1\n",
        "    )\n",
        "    outputs = detector(inputs)\n",
        "    model = tf.keras.Model(inputs=inputs, outputs=outputs)\n",
        "\n",
        "    # Compile with YOLOv8-specific loss\n",
        "    model.compile(\n",
        "        optimizer=\"adam\",\n",
        "        loss=YOLOV8Loss(\n",
        "            classification_loss=\"focal\",  # Focal loss for class predictions\n",
        "            box_loss=\"ciou\",              # CIoU loss for boxes\n",
        "            classification_weight=1.0,    # Adjust weights as needed\n",
        "            box_weight=1.0\n",
        "        ),\n",
        "    )\n",
        "    return model\n"
      ],
      "metadata": {
        "id": "urKl4Vs0R_r6"
      },
      "id": "urKl4Vs0R_r6",
      "execution_count": null,
      "outputs": []
    },
    {
      "id": "7241f987-3572-406d-8e10-26899603800d",
      "cell_type": "code",
      "source": [
        "\n",
        "model=create_ligh_model()\n",
        "model.build(input_shape=(None, 640, 640, 3))  # Batch size = None (linh hoạt)\n",
        "model.summary()"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-03-12T16:01:28.712149Z",
          "iopub.execute_input": "2025-03-12T16:01:28.712483Z",
          "execution_failed": "2025-03-12T16:02:31.063Z"
        },
        "id": "7241f987-3572-406d-8e10-26899603800d"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "9b96beb15e440db8",
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2025-03-12T06:31:06.008562Z",
          "start_time": "2025-03-12T06:30:55.830287Z"
        },
        "execution": {
          "execution_failed": "2025-03-12T16:02:31.063Z"
        },
        "trusted": true,
        "id": "9b96beb15e440db8"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "8ad1bb310a8b6724",
      "cell_type": "code",
      "source": [
        "tf.keras.utils.plot_model(model=model, show_shapes= True, dpi=76)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "execution_failed": "2025-03-12T16:02:31.064Z"
        },
        "id": "8ad1bb310a8b6724"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "e4150cc1-5dd3-4eee-8b17-0e80f2b0ed81",
      "cell_type": "code",
      "source": [
        "def define_hyperparameters(learning_rate=2e-5, decay_rate=0.99):\n",
        "    initial_learning_rate = learning_rate\n",
        "\n",
        "    lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n",
        "        initial_learning_rate,\n",
        "        decay_steps=100000,\n",
        "        decay_rate=0.96,\n",
        "        staircase=True\n",
        "    )\n",
        "\n",
        "    # Use the learning rate schedule in the optimizer\n",
        "    optimizer = tf.keras.optimizers.Adam(learning_rate=lr_schedule, beta_1=0.9, beta_2=0.999)\n",
        "    metrics = [tf.keras.metrics.Precision(),\n",
        "              tf.keras.metrics.Recall(),\n",
        "              tf.keras.metrics.IoU(num_classes=num_classes, target_class_ids=[1])\n",
        "             ]\n",
        "    return optimizer, metrics"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "execution_failed": "2025-03-12T16:02:31.064Z"
        },
        "id": "e4150cc1-5dd3-4eee-8b17-0e80f2b0ed81"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "989af633-ef93-4ad9-97a7-b5548232a98b",
      "cell_type": "code",
      "source": [
        "optimizer, metrics =define_hyperparameters()"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "execution_failed": "2025-03-12T16:02:31.064Z"
        },
        "id": "989af633-ef93-4ad9-97a7-b5548232a98b"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "2cc8eff2-6aa7-43cc-8e90-25efe7ca822b",
      "cell_type": "code",
      "source": [
        "for images, labels in train_dataset.take(1):\n",
        "    print(\"Images shape:\", images.shape)  # (8, 640, 640, 3)\n",
        "    print(\"Classes shape:\", labels[\"classes\"].shape)  # (8, 10, 1)\n",
        "    print(\"Boxes shape:\", labels[\"boxes\"].shape)  # (8, 10, 4)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "execution_failed": "2025-03-12T16:02:31.069Z"
        },
        "id": "2cc8eff2-6aa7-43cc-8e90-25efe7ca822b"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# from keras_cv.losses import CIoULoss\n",
        "\n",
        "# model.compile(\n",
        "#     optimizer=\"adam\",\n",
        "#     loss={\n",
        "#         'boxes': CIoULoss(bounding_box_format=\"xywh\"),  # Replace 'boxes' with actual output name\n",
        "#         'classes': 'categorical_crossentropy'           # Replace 'classes' with actual output name\n",
        "#     },\n",
        "#     # metrics=... (optional)\n",
        "# )"
      ],
      "metadata": {
        "id": "3dKWKilUUsSa"
      },
      "id": "3dKWKilUUsSa",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tf.config.optimizer.set_jit(False)  # Tắt XLA"
      ],
      "metadata": {
        "id": "qtgDQ4z9NyI1"
      },
      "id": "qtgDQ4z9NyI1",
      "execution_count": null,
      "outputs": []
    },
    {
      "id": "bf2efb5e-e26d-4545-854e-3476fee62f61",
      "cell_type": "code",
      "source": [
        "history = model.fit(\n",
        "    train_dataset,\n",
        "    validation_data=val_dataset,\n",
        "    epochs=epochs,\n",
        ")"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "execution_failed": "2025-03-12T16:02:31.069Z"
        },
        "id": "bf2efb5e-e26d-4545-854e-3476fee62f61"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "dg2EzFH0ekuO"
      },
      "id": "dg2EzFH0ekuO",
      "execution_count": null,
      "outputs": []
    }
  ]
}